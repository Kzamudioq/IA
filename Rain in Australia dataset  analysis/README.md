@Kzamudioq ¬øQu√© te parece el repositorio? ¬°Est√° chido! :+1:

<h1 align="center">
  <p align="center">:star: Bart Simpson te gu√≠a: Repositorio de predicci√≥n del clima en Australia, Man! :star:</p>
</h1>


`¬°Hola, soy Bart Simpson!`



<p align="center" width="100%">
    <img width="60%" src="https://github.com/Kzamudioq/IA/assets/138271936/66d219c8-e5f3-4040-8602-01874c9a4f05"> 
</p>

¬°Ey, man! Bienvenido a este proyecto loco donde estamos tratando de predecir el clima en Australia, mediate una base de datos extensa. Prep√°rate para una aventura salvaje en el mundo de los datos y los modelos de aprendizaje autom√°tico. ¬°Es como una monta√±a rusa, pero para tus neuronas!

## üß† **¬øQu√© rayos es este proyecto?** 


Aqu√≠ tienes la primicia: estamos tratando de ser los m√°s listos de la clase prediciendo el clima, estamos usando datos de los aeropuertos de Australia y aliment√°ndolos a nuestros modelos de aprendizaje autom√°tico para ver si pueden adivinar qu√© tiempo va a hacer el dia de ma√±ana. ¬°Es como una apuesta, pero con datos!


## üí° **Caracter√≠sticas Molonas** üí°

Vamos a hablar de las cosas geniales que estamos haciendo aqu√≠:

1. Modelos alucinantes: hemos lanzado toda la artiller√≠a pesada: Random Forest, Regresi√≥n Log√≠stica, LDA. Estos modelos son como los superh√©roes de la predicci√≥n del tiempo. ¬°Prep√°rate para verlos en acci√≥n!

2. Datos del clima: antes de alimentar a nuestros modelos con datos, tenemos que hacerles una manicura de datos. Eso significa limpiarlos, normalizarlos y prepararlos para la batalla. ¬°No hay lugar para datos desordenados en este proyecto!

### Paso 1: preparaci√≥n üöÄ

Primero las primeras, ¬øsabes? Importamos las herramientas necesarias, como pandas para manejar los datos, sklearn para entrenar los modelos y algunas otras cosas m√°s.

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import classification_report
```
### Paso 2: carga de datos üìä

Luego, metemos los datos en la batidora, aqu√≠ estamos cargando los datos del clima, ¬°eso es lo que necesitamos para hacer magia! [Kaggle Rain in Australia - Predict next-day rain in Australia](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package?resource=download)

<p align="center" width="100%">
    <img width="60%" src="https://github.com/Kzamudioq/IA/assets/138271936/8bcb4246-2399-46c6-9629-bff242b0dcdb"> 
</p>


```python
Data = pd.read_csv('weatherAUS.csv')
print('Tama√±o del dataset :', Data.shape)
```

### Paso 2: preprocesamiento üí™

El preprocesamiento de datos es como preparar la escena para una gran actuaci√≥n. As√≠ que, antes de que nuestros modelos puedan brillar en el escenario, tenemos que asegurarnos de que los datos est√©n en perfectas condiciones. Aqu√≠ te explico un poco m√°s sobre lo que hicimos:

#### Eliminaci√≥n de Valores Nulos üí•

Imagina que est√°s ensayando una obra y de repente un actor no aparece en el escenario. ¬°Vaya l√≠o! Bueno, los valores nulos en los datos son como esos actores desaparecidos. No podemos permitirnos tener datos faltantes porque podr√≠an arruinar toda la actuaci√≥n. As√≠ que, si encontramos valores nulos en nuestro conjunto de datos, los eliminamos sin piedad. ¬°No hay lugar para la vacilaci√≥n en el mundo del modelado de datos!

#### Normalizaci√≥n üìè

Ahora, la normalizaci√≥n es como ajustar las luces en el escenario para que todos los actores se vean igual de brillantes. En nuestro caso, queremos que todas las caracter√≠sticas de nuestros datos est√©n en la misma escala. Si una caracter√≠stica tiene valores muy grandes y otra tiene valores muy peque√±os, puede que nuestro modelo preste demasiada atenci√≥n a la que tiene valores grandes y se pierda la m√°s peque√±a. As√≠ que, utilizamos la normalizaci√≥n para asegurarnos de que todas las caracter√≠sticas est√©n en el mismo rango.

#### Tratamiento de Outliers üé≠

Los outliers son como esos momentos inesperados en una obra de teatro que hacen que todos se queden boquiabiertos. A veces, estos valores extremos pueden distorsionar nuestros modelos, as√≠ que tenemos que tratarlos con cuidado. Podemos eliminarlos, transformarlos o incluso dejarlos como est√°n, dependiendo de la situaci√≥n. Lo importante es asegurarnos de que no est√©n interfiriendo con el rendimiento general de nuestros modelos.

```python
#tratamiento de outliers.
def outlier_diagnostic_plots(df, variable):
    fig,axes = plt.subplots(1,3,figsize=(20,4))

    sns.histplot(df[variable], bins=30,ax=axes[0], kde=True)
    axes[0].set_title('Histograma')
    
    stats.probplot(df[variable], dist="norm", plot=axes[1])
    axes[1].set_title('QQ')
    
    # boxplot    
    sns.boxplot(y=df[variable],ax=axes[2])
    axes[2].set_title('Box&Whiskers')

outlier_diagnostic_plots(DataDarwin_missing, 'Evaporation')
```

<p align="center" width="100%">
    <img width="60%" src="https://github.com/Kzamudioq/IA/assets/138271936/e0472fc2-dd1e-4cda-a440-2c2637786a72"> 
</p>


#### Balanceo de clases ‚öñÔ∏è

El balanceo de datos es como asegurarnos de que todos los actores tengan el mismo tiempo en el escenario. Si una clase tiene muchos m√°s ejemplos que otra, nuestro modelo podr√≠a estar sesgado hacia la clase mayoritaria. Para evitar esto, podemos aplicar t√©cnicas de balanceo de datos como el sobremuestreo (oversampling) o el submuestreo (undersampling) para igualar el n√∫mero de ejemplos en cada clase y mejorar as√≠ la capacidad predictiva de nuestro modelo.


### Paso 4: entrenamiento y evaluaci√≥n üèãÔ∏è‚Äç‚ôÇÔ∏è

¬°Es hora de ense√±arle a estos modelos qui√©n manda aqu√≠! Vamos a entrenar un Random Forest, una Regresi√≥n Log√≠stica y un LDA.
Pero primero, vamos a preparar esos datos para entrenar a nuestros modelos, separaremos las caracter√≠sticas de las etiquetas y dividiremos los datos en conjuntos de entrenamiento y prueba.

```python

x_train_Darwin, x_test_Darwin, y_train_Darwin, y_test_Darwin = train_test_split(x_Darwin,y_Darwin,test_size=0.3,random_state = 42)
x_train_Perth, x_test_Perth, y_train_Perth, y_test_Perth = train_test_split(x_Perth,y_Perth,test_size=0.3,random_state = 42)
x_train_SydneyAirpor, x_test_SydneyAirpor, y_train_SydneyAirpor, y_test_SydneyAirpor =train_test_split(x_SydneyAirpor,y_SydneyAirpor,test_size=0.3,random_state = 42)
x_train_MelbourneAirport, x_test_MelbourneAirport, y_train_MelbourneAirport, y_test_MelbourneAirport = train_test_split(x_MelbourneAirport,y_MelbourneAirport,test_size=0.3,random_state = 42)

# Random Forest
rf_model = RandomForestClassifier()
rf_model.fit(x_train_SydneyAirpor_os, y_train_SydneyAirpor_os.values.ravel())
pred_rf = rf_model.predict(x_test_SydneyAirpor)
print(classification_report(y_test_SydneyAirpor,pred_rf))
print(rf_model.score(x_test_SydneyAirpor, y_test_SydneyAirpor))

# Regresi√≥n Log√≠stica
lr_model = LogisticRegression()
lr_model.fit(X_train_scaled, y_train)
lr_predictions = lr_model.predict(X_test_scaled)
lr_report = classification_report(y_test, lr_predictions)

# LDA
lda_model = LinearDiscriminantAnalysis()
lda_model.fit(X_train_scaled, y_train)
lda_predictions = lda_model.predict(X_test_scaled)
lda_report = classification_report(y_test, lda_predictions)

```


### Las M√©tricas! üèÜ

<p align="center" width="100%">
    <img width="60%" src="https://github.com/Kzamudioq/IA/assets/138271936/284d49e4-4115-4367-be0f-2cc9b9d2938a"> 
</p>


Ahora, la parte que realmente importa, ¬øno crees? Aqu√≠ tienes las m√©tricas de los modelos, como si fueran los puestos en una competencia de skate:

#### Random Forest:

- **Clase 0:**
  - Precision: 0.93
  - Recall: 0.94
  - F1-score: 0.93
- **Clase 1:**
  - Precision: 0.76
  - Recall: 0.72
  - F1-score: 0.74

#### Regresi√≥n Log√≠stica:
- **Clase 0:**
  - Precision: 0.90
  - Recall: 0.76
  - F1-score: 0.82
- **Clase 1:**
  - Precision: 0.50
  - Recall: 0.74
  - F1-score: 0.60
 

#### LDA:

- **Clase 0:**
  - Precision: 0.90
  - Recall: 0.78
  - F1-score: 0.84
- **Clase 1:**
  - Precision: 0.53
  - Recall: 0.74
  - F1-score: 0.62

## Pr√≥ximos Pasos üöÄ

Esto es solo el comienzo. En futuros repositorios, profundizaremos en modelos predictivos y m√°s. ¬°Mantente al tanto!




